<section id="research" class="home-section">
    <h1>Research Themes</h1>
    <p>
        MIRA focuses on multi-modal spectral imaging and fusion, including calibration, registration, and super-resolution.
    </p>
    <div class="research-grid">
        <a class="research-card">
            <img src="{{ site.baseurl }}/media/images/research/Imagerie-hyperspectrale.jpg" alt="Spectral Imaging">
            <span>Spectral Imaging</span>
        </a>

        <a class="research-card">
            <img src="{{ site.baseurl }}/media/images/research/registration.png" alt="Registration">
            <span>Registration</span>
        </a>

        <a class="research-card">
            <img src="{{ site.baseurl }}/media/images/research/main_sr.jpg" alt="Super-resolution">
            <span>Super-resolution</span>
        </a>
    </div>

    <div class="research-descriptions">

      <h3>Spectral Imaging</h3>
      <p>
        We acquire images that go beyond the visible range to capture detailed spectral information for each pixel.  
        Our workflow includes <b>preprocessing</b> and <b>radiometric calibration</b> of raw data to ensure accurate reflectance values and spectral consistency across sensors.  
        This enables reliable analysis of materials, biological tissues, and manufactured products using their unique optical signatures.
      </p>
    
      <div class="example-grid">
        <figure>
          <img src="{{ site.baseurl }}/media/images/research/frame_000002/lr_raw.png" alt="Raw HSI">
          <figcaption>Raw hyperspectral image (uncalibrated)</figcaption>
        </figure>
        <figure>
          <img src="{{ site.baseurl }}/media/images/research/frame_000002/lr_preprocessed.png" alt="Calibrated HSI">
          <figcaption>Radiometrically calibrated reflectance image</figcaption>
        </figure>
      </div>
    
    
      <h3>Image Registration</h3>
      <p>
        We align images from multiple cameras or sensors so that every pixel represents the same point in the scene.  
        This spatial matching is essential for combining data from color, infrared, and hyperspectral cameras accurately, ensuring high-quality fusion and comparison between modalities.
      </p>
    
      <div class="example-grid">
        <figure>
          <img src="{{ site.baseurl }}/media/images/research/frame_000002/hr_preprocessed.png" alt="Reference HR image">
          <figcaption>Reference image (HR)</figcaption>
        </figure>
        <figure>
          <img src="{{ site.baseurl }}/media/images/research/frame_000002/lr_preprocessed.png" alt="Target LR image">
          <figcaption>Target image (LR, before alignment)</figcaption>
        </figure>
        <figure>
          <img src="{{ site.baseurl }}/media/images/research/frame_000002/lr_aligned.png" alt="Registered LR image">
          <figcaption>Target image after registration</figcaption>
        </figure>
      </div>
    
    
      <h3>Super-resolution</h3>
      <p>
        We combine information from multiple low-resolution images or sensors to produce sharper, higher-resolution results.  
        This enhances image detail and clarity, enabling improved visualization, quantitative analysis, and advanced applications such as defect detection and material mapping.
      </p>
    
      <div class="example-grid">
        <figure>
          <img src="{{ site.baseurl }}/media/images/research/frame_000002/zoom/hr_aligned.png" alt="Registered HR image">
          <figcaption>Registered HR image</figcaption>
        </figure>
        <figure>
          <img src="{{ site.baseurl }}/media/images/research/frame_000002/zoom/lr_aligned.png" alt="Registered LR image">
          <figcaption>Registered LR image</figcaption>
        </figure>
        <figure>
          <img src="{{ site.baseurl }}/media/images/research/frame_000002/zoom/sr_fused.png" alt="Super-resolved image">
          <figcaption>Super-resolved fusion result</figcaption>
        </figure>
      </div>
    
    </div>
            
    <h2 style="justify-content: center;">Super-resolution</h2>

    <p>
      In multimodal imaging, different cameras often capture complementary information.  
      <b>Cam&nbsp;1</b> provides rich spectral data but lower spatial detail,  
      while <b>Cam&nbsp;2</b> offers sharper spatial resolution with fewer spectral bands.  
      Through <b>super-resolution fusion</b>, these data sources are combined to produce an image
      that is both spatially detailed and spectrally rich, as summarized below:
    </p>
    
    <table class="fusion-table">
      <thead>
        <tr>
          <th>Camera / Result</th>
          <th>Spectral Resolution</th>
          <th>Spatial Resolution</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><b>Cam&nbsp;1</b></td>
          <td>High</td>
          <td>Low</td>
          <td>Captures detailed spectral information for material analysis.</td>
        </tr>
        <tr>
          <td><b>Cam&nbsp;2</b></td>
          <td>Low</td>
          <td>High</td>
          <td>Captures fine spatial structures with fewer spectral bands.</td>
        </tr>
        <tr>
          <td><b>Fused Image</b></td>
          <td>High</td>
          <td>High</td>
          <td>Combines both to yield enhanced spatial and spectral quality.</td>
        </tr>
      </tbody>
    </table>
    
    <p>
      The video and sliders below demonstrate this process â€” showing how two complementary inputs  
      are merged into a high-resolution spectral image.
    </p>
    
    <h3 style="justify-content: center;">Video Illustration</h3>

    <div class="legend">
      <span><b>LR</b> = Low Resolution (coarser spatial detail)</span>
      <span><b>HR</b> = High Resolution (finer spatial detail)</span>
    </div>
    
    <div class="video-grid">
      <video autoplay loop muted playsinline>
        {% assign video_media_dir = site.baseurl | append: '/' | append: 'media/tech-and-fest-2025/images/pair_1/frame_0000' %}
        <source src="{{ video_media_dir }}/comparison.webm" type="video/webm">
        Your browser does not support the video tag.
      </video>
    </div>
    
    <h3 style="justify-content: center;">Comparison Sliders</h3>

    <div class="legend">
      <span><b>LR</b> = Low Resolution (coarser spatial detail)</span>
      <span><b>HR</b> = High Resolution (finer spatial detail)</span>
    </div>
    
    <div class="tri-sliders-container">
      <div style="width: 50%;">
        {% assign slider_media_dir = site.baseurl | append: '/' | append: 'media/tech-and-fest-2025/images/pair_1/frame_0000' %}
        {% assign left_before = slider_media_dir | append: "/lr_highlight.png" %}
        {% assign left_after  = slider_media_dir | append: "/sr_highlight.png" %}
        {% assign top_before  = slider_media_dir | append: "/lr_patch.png" %}
        {% assign top_after   = slider_media_dir | append: "/sr_patch.png" %}
        {% assign bottom_before = slider_media_dir | append: "/hr_spectrum.png" %}
        {% assign bottom_after  = slider_media_dir | append: "/sr_spectrum.png" %}
        {% include tri_slider.html
        left_before=left_before
        left_after=left_after
        left_label_before="Cam 1 (LR)"
        left_label_after="Fusion (HR)"
        top_before=top_before
        top_after=top_after
        top_label_before="Cam 1"
        top_label_after="Fusion"
        bottom_before=bottom_before
        bottom_after=bottom_after
        bottom_label_before="Cam 2"
        bottom_label_after="Fusion"
        %}
      </div>
    </div>

</section>
